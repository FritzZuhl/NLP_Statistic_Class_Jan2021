{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial 04 - Vector based Text Feature Representations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVbT16TDx5nJ"
      },
      "source": [
        "# Tutorial 4: Vectorized Text Representations\n",
        "\n",
        "## Exploring Traditional Statistical Models\n",
        "\n",
        "Feature Engineering is often known as the secret sauce to creating superior and better performing machine learning models.\n",
        "\n",
        "Just one excellent feature could be your ticket to winning a Kaggle challenge or getting the best model to be deployed in the enterprise! \n",
        "\n",
        "The importance of feature engineering is even more important for unstructured, textual data because we need to convert free flowing text into some numeric representations which can then be understood by machine learning algorithms.\n",
        "\n",
        "Here we will explore the following feature engineering techniques:\n",
        "\n",
        "+ Bag of Words Model (TF)\n",
        "+ Bag of N-grams Model\n",
        "+ TF-IDF Model\n",
        "+ Document Similarity \n",
        "+ Topic Model Features\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbpO9CA64p6n"
      },
      "source": [
        "## Prepare Corpus\n",
        "\n",
        "Let’s now take a sample corpus of documents on which we will run most of our analyses in this article. A corpus is typically a collection of text documents usually belonging to one or more subjects or domains."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hetEmWBwCiEJ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "pd.options.display.max_colwidth = 200"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0EI0I084vP9"
      },
      "source": [
        "corpus = ['The sky is blue and beautiful.',\n",
        "          'Love this blue and beautiful sky!',\n",
        "          'The quick brown fox jumps over the lazy dog.',\n",
        "          \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\",\n",
        "          'I love green eggs, ham, sausages and bacon!',\n",
        "          'The brown fox is quick and the blue dog is lazy!',\n",
        "          'The sky is very blue and the sky is very beautiful today',\n",
        "          'The dog is lazy but the brown fox is quick!'    \n",
        "]\n",
        "labels = ['weather', 'weather', 'animals', 'food', 'food', 'animals', 'weather', 'animals']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDpXbGjO4wvg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "7e86f625-5f6b-4ef4-9571-bc6c701e36fe"
      },
      "source": [
        "corpus = np.array(corpus)\n",
        "corpus_df = pd.DataFrame({'Document': corpus, \n",
        "                          'Category': labels})\n",
        "corpus_df = corpus_df[['Document', 'Category']]\n",
        "corpus_df"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The sky is blue and beautiful.</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this blue and beautiful sky!</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The dog is lazy but the brown fox is quick!</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                             Document Category\n",
              "0                                      The sky is blue and beautiful.  weather\n",
              "1                                   Love this blue and beautiful sky!  weather\n",
              "2                        The quick brown fox jumps over the lazy dog.  animals\n",
              "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans     food\n",
              "4                         I love green eggs, ham, sausages and bacon!     food\n",
              "5                    The brown fox is quick and the blue dog is lazy!  animals\n",
              "6            The sky is very blue and the sky is very beautiful today  weather\n",
              "7                         The dog is lazy but the brown fox is quick!  animals"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w4ra8_540cx"
      },
      "source": [
        "## Simple Preprocessing\n",
        "\n",
        "Since the focus of this unit is on feature engineering, we will build a simple text pre-processor which focuses on removing special characters, extra whitespaces, digits, stopwords and lower casing the text corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQCOflcB4x7z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ff6f4f-e8e0-43fc-bf0a-30089a441d4f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kxGpB9i4xze"
      },
      "source": [
        "import nltk\n",
        "import re"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFBkyuNh5Szb"
      },
      "source": [
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def normalize_document(doc):\n",
        "    # lower case and remove special characters\\whitespaces\n",
        "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
        "    doc = doc.lower()\n",
        "    doc = doc.strip()\n",
        "    # tokenize document\n",
        "    tokens = nltk.word_tokenize(doc)\n",
        "    # filter stopwords out of document\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    # re-create document from filtered tokens\n",
        "    doc = ' '.join(filtered_tokens)\n",
        "    return doc"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA0CxIbd5U08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "286389ef-d50a-4aec-cb3d-039c254af428"
      },
      "source": [
        "normalize_corpus = np.vectorize(normalize_document)\n",
        "\n",
        "norm_corpus = normalize_corpus(corpus)\n",
        "norm_corpus"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['sky blue beautiful', 'love blue beautiful sky',\n",
              "       'quick brown fox jumps lazy dog',\n",
              "       'kings breakfast sausages ham bacon eggs toast beans',\n",
              "       'love green eggs ham sausages bacon',\n",
              "       'brown fox quick blue dog lazy', 'sky blue sky beautiful today',\n",
              "       'dog lazy brown fox quick'], dtype='<U51')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2nzoLBB5X9s"
      },
      "source": [
        "## Bag of Words Model\n",
        "\n",
        "This is perhaps the most simple vector space representational model for unstructured text. \n",
        "\n",
        "A vector space model is simply a mathematical model to represent unstructured text (or any other data) as numeric vectors, such that each dimension of the vector is a specific feature\\attribute. \n",
        "\n",
        "The bag of words model represents each text document as a numeric vector where each dimension is a specific word from the corpus and the value could be its frequency in the document, occurrence (denoted by 1 or 0) or even weighted values. \n",
        "\n",
        "The model’s name is such because each document is represented literally as a ‘bag’ of its own words, disregarding word orders, sequences and grammar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tdc_-W_5Xnu"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkjkq8TA5dP_"
      },
      "source": [
        "# get bag of words features in sparse format\n",
        "cv = CountVectorizer(min_df=0., max_df=1.)\n",
        "cv_matrix = cv.fit_transform(norm_corpus)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE6a-pddRSc_",
        "outputId": "0d5cb9a3-caaf-470d-ab78-8ae0dcc3fb5a"
      },
      "source": [
        "cv_matrix"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<8x20 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 42 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqlcZhYMRO4y",
        "outputId": "d7579929-cb5f-4e82-edb8-d987ad387e36"
      },
      "source": [
        "# view non-zero feature positions in the sparse matrix\r\n",
        "print(cv_matrix)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 17)\t1\n",
            "  (0, 3)\t1\n",
            "  (0, 2)\t1\n",
            "  (1, 17)\t1\n",
            "  (1, 3)\t1\n",
            "  (1, 2)\t1\n",
            "  (1, 14)\t1\n",
            "  (2, 15)\t1\n",
            "  (2, 5)\t1\n",
            "  (2, 8)\t1\n",
            "  (2, 11)\t1\n",
            "  (2, 13)\t1\n",
            "  (2, 6)\t1\n",
            "  (3, 12)\t1\n",
            "  (3, 4)\t1\n",
            "  (3, 16)\t1\n",
            "  (3, 10)\t1\n",
            "  (3, 0)\t1\n",
            "  (3, 7)\t1\n",
            "  (3, 18)\t1\n",
            "  (3, 1)\t1\n",
            "  (4, 14)\t1\n",
            "  (4, 16)\t1\n",
            "  (4, 10)\t1\n",
            "  (4, 0)\t1\n",
            "  (4, 7)\t1\n",
            "  (4, 9)\t1\n",
            "  (5, 3)\t1\n",
            "  (5, 15)\t1\n",
            "  (5, 5)\t1\n",
            "  (5, 8)\t1\n",
            "  (5, 13)\t1\n",
            "  (5, 6)\t1\n",
            "  (6, 17)\t2\n",
            "  (6, 3)\t1\n",
            "  (6, 2)\t1\n",
            "  (6, 19)\t1\n",
            "  (7, 15)\t1\n",
            "  (7, 5)\t1\n",
            "  (7, 8)\t1\n",
            "  (7, 13)\t1\n",
            "  (7, 6)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3mSRqJ4RVtf"
      },
      "source": [
        "The feature matrix is traditionally represented as a sparse matrix since the number of features increase phenomenally with each document considering each distinct word becomes a feature. \r\n",
        "\r\n",
        "The preceding output tells us for each (x, y) pair what is the total count. \r\n",
        "\r\n",
        "Here x represents a document and y represents a specific word\\feature and the value is the number of times y occurs in x.\r\n",
        "\r\n",
        "We can leverage the following code to view the output in a dense matrix representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nybsF_ORKyn",
        "outputId": "9e3cb221-cf6c-4a8b-a65f-efe4aaf90fbe"
      },
      "source": [
        "cv_matrix = cv_matrix.toarray()\r\n",
        "cv_matrix"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0],\n",
              "       [1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tODJc4p45wfq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "5a11061a-250e-4422-80e3-dce7ba091d57"
      },
      "source": [
        "# get all unique words in the corpus\n",
        "vocab = cv.get_feature_names()\n",
        "# show document feature vectors\n",
        "pd.DataFrame(cv_matrix, columns=vocab)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bacon</th>\n",
              "      <th>beans</th>\n",
              "      <th>beautiful</th>\n",
              "      <th>blue</th>\n",
              "      <th>breakfast</th>\n",
              "      <th>brown</th>\n",
              "      <th>dog</th>\n",
              "      <th>eggs</th>\n",
              "      <th>fox</th>\n",
              "      <th>green</th>\n",
              "      <th>ham</th>\n",
              "      <th>jumps</th>\n",
              "      <th>kings</th>\n",
              "      <th>lazy</th>\n",
              "      <th>love</th>\n",
              "      <th>quick</th>\n",
              "      <th>sausages</th>\n",
              "      <th>sky</th>\n",
              "      <th>toast</th>\n",
              "      <th>today</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bacon  beans  beautiful  blue  breakfast  ...  quick  sausages  sky  toast  today\n",
              "0      0      0          1     1          0  ...      0         0    1      0      0\n",
              "1      0      0          1     1          0  ...      0         0    1      0      0\n",
              "2      0      0          0     0          0  ...      1         0    0      0      0\n",
              "3      1      1          0     0          1  ...      0         1    0      1      0\n",
              "4      1      0          0     0          0  ...      0         1    0      0      0\n",
              "5      0      0          0     1          0  ...      1         0    0      0      0\n",
              "6      0      0          1     1          0  ...      0         0    2      0      1\n",
              "7      0      0          0     0          0  ...      1         0    0      0      0\n",
              "\n",
              "[8 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnqTlKIaRrGn"
      },
      "source": [
        "You can clearly see that each column or dimension in the feature vectors represents a word from the corpus and each row represents one of our documents. \r\n",
        "\r\n",
        "The value in any cell, represents the number of times that word (represented by column) occurs in the specific document (represented by row). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HwpTUOD5z7N"
      },
      "source": [
        "## Bag of N-Grams Model\n",
        "\n",
        "A word is just a single token, often known as a unigram or 1-gram. We already know that the Bag of Words model doesn’t consider order of words. But what if we also wanted to take into account phrases or collection of words which occur in a sequence? \n",
        "\n",
        "N-grams help us achieve that. An N-gram is basically a collection of word tokens from a text document such that these tokens are contiguous and occur in a sequence. \n",
        "\n",
        "Bi-grams indicate n-grams of order 2 (two words), Tri-grams indicate n-grams of order 3 (three words), and so on. \n",
        "\n",
        "The Bag of N-Grams model is hence just an extension of the Bag of Words model so we can also leverage N-gram based features. The following example depicts bi-gram based features in each document feature vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMVEZovT53Cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "1c2ad52c-6614-4aef-e512-3b7d87ff4ba9"
      },
      "source": [
        "# you can set the n-gram range to 1,2 to get unigrams as well as bigrams\n",
        "bv = CountVectorizer(ngram_range=(2,2))\n",
        "bv_matrix = bv.fit_transform(norm_corpus)\n",
        "\n",
        "bv_matrix = bv_matrix.toarray()\n",
        "vocab = bv.get_feature_names()\n",
        "pd.DataFrame(bv_matrix, columns=vocab)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bacon eggs</th>\n",
              "      <th>beautiful sky</th>\n",
              "      <th>beautiful today</th>\n",
              "      <th>blue beautiful</th>\n",
              "      <th>blue dog</th>\n",
              "      <th>blue sky</th>\n",
              "      <th>breakfast sausages</th>\n",
              "      <th>brown fox</th>\n",
              "      <th>dog lazy</th>\n",
              "      <th>eggs ham</th>\n",
              "      <th>eggs toast</th>\n",
              "      <th>fox jumps</th>\n",
              "      <th>fox quick</th>\n",
              "      <th>green eggs</th>\n",
              "      <th>ham bacon</th>\n",
              "      <th>ham sausages</th>\n",
              "      <th>jumps lazy</th>\n",
              "      <th>kings breakfast</th>\n",
              "      <th>lazy brown</th>\n",
              "      <th>lazy dog</th>\n",
              "      <th>love blue</th>\n",
              "      <th>love green</th>\n",
              "      <th>quick blue</th>\n",
              "      <th>quick brown</th>\n",
              "      <th>sausages bacon</th>\n",
              "      <th>sausages ham</th>\n",
              "      <th>sky beautiful</th>\n",
              "      <th>sky blue</th>\n",
              "      <th>toast beans</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bacon eggs  beautiful sky  ...  sky blue  toast beans\n",
              "0           0              0  ...         1            0\n",
              "1           0              1  ...         0            0\n",
              "2           0              0  ...         0            0\n",
              "3           1              0  ...         0            1\n",
              "4           0              0  ...         0            0\n",
              "5           0              0  ...         0            0\n",
              "6           0              0  ...         1            0\n",
              "7           0              0  ...         0            0\n",
              "\n",
              "[8 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdM_PdKE57mN"
      },
      "source": [
        "## TF-IDF Model\n",
        "\n",
        "There are some potential problems which might arise with the Bag of Words model when it is used on large corpora. Since the feature vectors are based on absolute term frequencies, there might be some terms which occur frequently across all documents and these may tend to overshadow other terms in the feature set.\n",
        "\n",
        "The TF-IDF model tries to combat this issue by using a scaling or normalizing factor in its computation. TF-IDF stands for Term Frequency-Inverse Document Frequency, which uses a combination of two metrics in its computation, namely: term frequency (tf) and inverse document frequency (idf). \n",
        "\n",
        "This technique was developed for ranking results for queries in search engines and now it is an indispensable model in the world of information retrieval and NLP.\n",
        "\n",
        "Mathematically, we can define TF-IDF as $$tfidf = tf \\times idf$$\n",
        "\n",
        "which can be expanded further to be represented as follows.\n",
        "\n",
        "\n",
        "\n",
        "Here, $tf-idf(w, D)$ is the TF-IDF score for word $w$ in document $D$.\n",
        "\n",
        "- The term $tf(w, D)$ represents the term frequency of the word $w$ in document $D$, which can be obtained from the Bag of Words model.\n",
        "- The term $idf(w, D)$ is the inverse document frequency for the term $w$, which can be computed as the log transform of the total number of documents in the corpus $C$ divided by the document frequency of the word $w$, which is basically the frequency of documents in the corpus where the word w occurs (number of times word $w$ occurs across all documents).\n",
        "\n",
        "In most implementations, the tfidf matrix is normalized by dividing it with the L2 norm of the matrix also known as the Euclidean norm (which is the square root of the sum of the square of each term's tfidf weight)\n",
        "\n",
        "There are multiple variants of this model but they all end up giving quite similar results. Let’s apply this on our corpus now!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRwu44IHTdkt"
      },
      "source": [
        "### Using TF-IDF Transformer\r\n",
        "\r\n",
        "The following code shows us an implementation of getting the tfidf based feature vectors considering we already have our bag of words feature vectors which we had obtained in a previous section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "vEBSeVS4TiLm",
        "outputId": "92f102ce-4e39-48ee-ccd3-fe3928bb9942"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
        "\r\n",
        "tt = TfidfTransformer(norm='l2', use_idf=True)\r\n",
        "tt_matrix = tt.fit_transform(cv_matrix)\r\n",
        "\r\n",
        "tt_matrix = tt_matrix.toarray()\r\n",
        "vocab = cv.get_feature_names()\r\n",
        "pd.DataFrame(np.round(tt_matrix, 2), columns=vocab)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bacon</th>\n",
              "      <th>beans</th>\n",
              "      <th>beautiful</th>\n",
              "      <th>blue</th>\n",
              "      <th>breakfast</th>\n",
              "      <th>brown</th>\n",
              "      <th>dog</th>\n",
              "      <th>eggs</th>\n",
              "      <th>fox</th>\n",
              "      <th>green</th>\n",
              "      <th>ham</th>\n",
              "      <th>jumps</th>\n",
              "      <th>kings</th>\n",
              "      <th>lazy</th>\n",
              "      <th>love</th>\n",
              "      <th>quick</th>\n",
              "      <th>sausages</th>\n",
              "      <th>sky</th>\n",
              "      <th>toast</th>\n",
              "      <th>today</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.32</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bacon  beans  beautiful  blue  ...  sausages   sky  toast  today\n",
              "0   0.00   0.00       0.60  0.53  ...      0.00  0.60   0.00    0.0\n",
              "1   0.00   0.00       0.49  0.43  ...      0.00  0.49   0.00    0.0\n",
              "2   0.00   0.00       0.00  0.00  ...      0.00  0.00   0.00    0.0\n",
              "3   0.32   0.38       0.00  0.00  ...      0.32  0.00   0.38    0.0\n",
              "4   0.39   0.00       0.00  0.00  ...      0.39  0.00   0.00    0.0\n",
              "5   0.00   0.00       0.00  0.37  ...      0.00  0.00   0.00    0.0\n",
              "6   0.00   0.00       0.36  0.32  ...      0.00  0.72   0.00    0.5\n",
              "7   0.00   0.00       0.00  0.00  ...      0.00  0.00   0.00    0.0\n",
              "\n",
              "[8 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEHdgzX-T2b7"
      },
      "source": [
        "### Using TF-IDF Vectorizer\r\n",
        "\r\n",
        "You don't always need to generate features beforehand using a Bag of Words - count based model before engineering TF-IDF features. The TfidfVectorizer by scikit-learn enables us to directly compute the tfidf vectors by taking the raw documents themselves as input and internally computing the term frequencies as well as the inverse document frequencies "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isn9YM6j6L4K"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9S5RG-36PI3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "5f006a7f-a52d-43ed-c161-230dd6b3be1f"
      },
      "source": [
        "tv = TfidfVectorizer(min_df=0., max_df=1., norm='l2', use_idf=True)\n",
        "tv_matrix = tv.fit_transform(norm_corpus)\n",
        "tv_matrix = tv_matrix.toarray()\n",
        "\n",
        "vocab = tv.get_feature_names()\n",
        "pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bacon</th>\n",
              "      <th>beans</th>\n",
              "      <th>beautiful</th>\n",
              "      <th>blue</th>\n",
              "      <th>breakfast</th>\n",
              "      <th>brown</th>\n",
              "      <th>dog</th>\n",
              "      <th>eggs</th>\n",
              "      <th>fox</th>\n",
              "      <th>green</th>\n",
              "      <th>ham</th>\n",
              "      <th>jumps</th>\n",
              "      <th>kings</th>\n",
              "      <th>lazy</th>\n",
              "      <th>love</th>\n",
              "      <th>quick</th>\n",
              "      <th>sausages</th>\n",
              "      <th>sky</th>\n",
              "      <th>toast</th>\n",
              "      <th>today</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.32</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bacon  beans  beautiful  blue  ...  sausages   sky  toast  today\n",
              "0   0.00   0.00       0.60  0.53  ...      0.00  0.60   0.00    0.0\n",
              "1   0.00   0.00       0.49  0.43  ...      0.00  0.49   0.00    0.0\n",
              "2   0.00   0.00       0.00  0.00  ...      0.00  0.00   0.00    0.0\n",
              "3   0.32   0.38       0.00  0.00  ...      0.32  0.00   0.38    0.0\n",
              "4   0.39   0.00       0.00  0.00  ...      0.39  0.00   0.00    0.0\n",
              "5   0.00   0.00       0.00  0.37  ...      0.00  0.00   0.00    0.0\n",
              "6   0.00   0.00       0.36  0.32  ...      0.00  0.72   0.00    0.5\n",
              "7   0.00   0.00       0.00  0.00  ...      0.00  0.00   0.00    0.0\n",
              "\n",
              "[8 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwHbcNa5UJ0_"
      },
      "source": [
        "## Extracting Features for New Documents\r\n",
        "\r\n",
        "Suppose you have built a machine learning model to classify and categorize news articles and it in currently in production. \r\n",
        "\r\n",
        "How will you generate features for completely new documents so that we can feed it into our machine learning models for predictions? \r\n",
        "\r\n",
        "The scikit-learn API provides the `transform(…)` function for the vectorizers we discussed previously and we can leverage the same to get features for a completely new document which was not present in our corpus previously (when we trained our model in the past)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "G7ULfvPdUSYK",
        "outputId": "568e73fb-96db-40cc-af25-14c4d7a1818b"
      },
      "source": [
        "new_doc = 'the sky is green today'\r\n",
        "pd.DataFrame(np.round(tv.transform([new_doc]).toarray(), 2), \r\n",
        "             columns=tv.get_feature_names())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bacon</th>\n",
              "      <th>beans</th>\n",
              "      <th>beautiful</th>\n",
              "      <th>blue</th>\n",
              "      <th>breakfast</th>\n",
              "      <th>brown</th>\n",
              "      <th>dog</th>\n",
              "      <th>eggs</th>\n",
              "      <th>fox</th>\n",
              "      <th>green</th>\n",
              "      <th>ham</th>\n",
              "      <th>jumps</th>\n",
              "      <th>kings</th>\n",
              "      <th>lazy</th>\n",
              "      <th>love</th>\n",
              "      <th>quick</th>\n",
              "      <th>sausages</th>\n",
              "      <th>sky</th>\n",
              "      <th>toast</th>\n",
              "      <th>today</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bacon  beans  beautiful  blue  ...  sausages   sky  toast  today\n",
              "0    0.0    0.0        0.0   0.0  ...       0.0  0.46    0.0   0.63\n",
              "\n",
              "[1 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_H3UgA76W9e"
      },
      "source": [
        "## Document Similarity\n",
        "\n",
        "Document similarity is the process of using a distance or similarity based metric that can be used to identify how similar a text document is with any other document(s) based on features extracted from the documents like bag of words or tf-idf.\n",
        "\n",
        "Thus you can see that we can build on top of the tf-idf based features we engineered in the previous section and use them to generate new features which can be useful in domains like search engines, document clustering and information retrieval by leveraging these similarity based features.\n",
        "\n",
        "Pairwise document similarity in a corpus involves computing document similarity for each pair of documents in a corpus. Thus if you have C documents in a corpus, you would end up with a C x C matrix such that each row and column represents the similarity score for a pair of documents, which represent the indices at the row and column, respectively. There are several similarity and distance metrics that are used to compute document similarity. \n",
        "\n",
        "These include cosine distance/similarity, euclidean distance, manhattan distance, BM25 similarity, jaccard distance and so on. In our analysis, we will be using perhaps the most popular and widely used similarity metric, cosine similarity and compare pairwise document similarity based on their TF-IDF feature vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARHymFty6bgI"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPjoUC9b6c_3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "a7d742dc-29a4-4c88-a22d-415de4dcaa21"
      },
      "source": [
        "similarity_matrix = cosine_similarity(tv_matrix)\n",
        "similarity_df = pd.DataFrame(similarity_matrix)\n",
        "similarity_df"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.820599</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.192353</td>\n",
              "      <td>0.817246</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.820599</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.225489</td>\n",
              "      <td>0.157845</td>\n",
              "      <td>0.670631</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.791821</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.850516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.506866</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.225489</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.506866</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.192353</td>\n",
              "      <td>0.157845</td>\n",
              "      <td>0.791821</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.115488</td>\n",
              "      <td>0.930989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.817246</td>\n",
              "      <td>0.670631</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.115488</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.850516</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.930989</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2  ...         5         6         7\n",
              "0  1.000000  0.820599  0.000000  ...  0.192353  0.817246  0.000000\n",
              "1  0.820599  1.000000  0.000000  ...  0.157845  0.670631  0.000000\n",
              "2  0.000000  0.000000  1.000000  ...  0.791821  0.000000  0.850516\n",
              "3  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "4  0.000000  0.225489  0.000000  ...  0.000000  0.000000  0.000000\n",
              "5  0.192353  0.157845  0.791821  ...  1.000000  0.115488  0.930989\n",
              "6  0.817246  0.670631  0.000000  ...  0.115488  1.000000  0.000000\n",
              "7  0.000000  0.000000  0.850516  ...  0.930989  0.000000  1.000000\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ynf7GhV6gHp"
      },
      "source": [
        "Cosine similarity basically gives us a metric representing the cosine of the angle between the feature vector representations of two text documents. Lower the angle between the documents, the closer and more similar they are as depicted in the following figure.\n",
        "\n",
        "\n",
        "\n",
        "Looking closely at the similarity matrix clearly tells us that documents (0, 1 and 6), (2, 5 and 7) are very similar to one another and documents 3 and 4 are slightly similar to each other but the magnitude is not very strong, however still stronger than the other documents. This must indicate these similar documents have some similar features. This is a perfect example of grouping or clustering that can be solved by unsupervised learning especially when you are dealing with huge corpora of millions of text documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5a64gwy6lNu"
      },
      "source": [
        "## Bonus: Document Clustering on Similarity Features\n",
        "\n",
        "We will use a very popular partition based clustering method, K-means clustering to cluster or group these documents based on their similarity based feature representations. \n",
        "\n",
        "In K-means clustering, we have an input parameter k, which specifies the number of clusters it will output using the document features. This clustering method is a centroid based clustering method, where it tries to cluster these documents into clusters of equal variance. It tries to create these clusters by minimizing the within-cluster sum of squares measure, also known as inertia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0DIt6hw6gdr"
      },
      "source": [
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQPVbM016rVJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "046a3fab-7314-4e05-c954-dc3339b1c6a7"
      },
      "source": [
        "km = KMeans(n_clusters=3, random_state=0)\n",
        "km.fit_transform(similarity_matrix)\n",
        "cluster_labels = km.labels_\n",
        "cluster_labels = pd.DataFrame(cluster_labels, columns=['ClusterLabel'])\n",
        "pd.concat([corpus_df, cluster_labels], axis=1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Category</th>\n",
              "      <th>ClusterLabel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The sky is blue and beautiful.</td>\n",
              "      <td>weather</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this blue and beautiful sky!</td>\n",
              "      <td>weather</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
              "      <td>animals</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
              "      <td>food</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
              "      <td>food</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
              "      <td>animals</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
              "      <td>weather</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The dog is lazy but the brown fox is quick!</td>\n",
              "      <td>animals</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                             Document  ... ClusterLabel\n",
              "0                                      The sky is blue and beautiful.  ...            2\n",
              "1                                   Love this blue and beautiful sky!  ...            2\n",
              "2                        The quick brown fox jumps over the lazy dog.  ...            1\n",
              "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans  ...            0\n",
              "4                         I love green eggs, ham, sausages and bacon!  ...            0\n",
              "5                    The brown fox is quick and the blue dog is lazy!  ...            1\n",
              "6            The sky is very blue and the sky is very beautiful today  ...            2\n",
              "7                         The dog is lazy but the brown fox is quick!  ...            1\n",
              "\n",
              "[8 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F57lkgRWU36Y"
      },
      "source": [
        "Thus you can clearly see our algorithm has correctly identified the three distinct categories in our documents based on the cluster labels assigned to them. This should give you a good idea of how our TF-IDF features were leveraged to build our similarity features which in turn helped in clustering our documents. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaS7enjaU-CD"
      },
      "source": [
        "## Topic Model Features\r\n",
        "\r\n",
        "While we will be covering topic modeling in detail in a separate module, a discussion about feature engineering is not complete without talking about topic models. \r\n",
        "\r\n",
        "The idea of topic models revolves around the process of extracting key themes or concepts from a corpus of documents which are represented as topics. \r\n",
        "\r\n",
        "Each topic can be represented as a bag or collection of words/terms from the document corpus. Together, these terms signify a specific topic, theme or a concept and each topic can be easily distinguished from other topics by virtue of the semantic meaning conveyed by these terms. \r\n",
        "\r\n",
        "\r\n",
        "![](https://i.imgur.com/MeroIZm.png)\r\n",
        "\r\n",
        "\r\n",
        "There are topic models like Latent Dirichlet Allocation (LDA), which uses a generative probabilistic model where each document consists of a combination of several topics and each term or word can be assigned to a specific topic.\r\n",
        "\r\n",
        "For the purpose of feature engineering which is the intent of this tutorial, you need to remember that when LDA is applied on a document-term matrix (TF-IDF or Bag of Words feature matrix), it gets decomposed into two main components.\r\n",
        "\r\n",
        "\r\n",
        "- A document-topic matrix, which would be the feature matrix we\r\n",
        "are looking for.\r\n",
        "- A topic-term matrix, which helps us in looking at potential topics in the corpus.\r\n",
        "\r\n",
        "\r\n",
        "Let’s now leverage scikit-learn to get the document-topic matrix as follows, which can be used as features for any subsequent modeling requirements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "r50DQNHAUz6R",
        "outputId": "b02b5d38-5d0f-4a12-b52e-f2ec7fc6b52a"
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\r\n",
        "\r\n",
        "# We know here our corpus has three types of topics. \r\n",
        "# Usually you might have to play around with this number (hyperparameter)\r\n",
        "lda = LatentDirichletAllocation(n_components=3, max_iter=10000, random_state=0)\r\n",
        "dt_matrix = lda.fit_transform(cv_matrix)\r\n",
        "features = pd.DataFrame(dt_matrix, columns=['T1', 'T2', 'T3'])\r\n",
        "features"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T1</th>\n",
              "      <th>T2</th>\n",
              "      <th>T3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.832191</td>\n",
              "      <td>0.083480</td>\n",
              "      <td>0.084329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.863554</td>\n",
              "      <td>0.069100</td>\n",
              "      <td>0.067346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.047794</td>\n",
              "      <td>0.047776</td>\n",
              "      <td>0.904430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.037243</td>\n",
              "      <td>0.925559</td>\n",
              "      <td>0.037198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.049121</td>\n",
              "      <td>0.903076</td>\n",
              "      <td>0.047802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.054902</td>\n",
              "      <td>0.047778</td>\n",
              "      <td>0.897321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.888287</td>\n",
              "      <td>0.055697</td>\n",
              "      <td>0.056016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.055704</td>\n",
              "      <td>0.055689</td>\n",
              "      <td>0.888607</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         T1        T2        T3\n",
              "0  0.832191  0.083480  0.084329\n",
              "1  0.863554  0.069100  0.067346\n",
              "2  0.047794  0.047776  0.904430\n",
              "3  0.037243  0.925559  0.037198\n",
              "4  0.049121  0.903076  0.047802\n",
              "5  0.054902  0.047778  0.897321\n",
              "6  0.888287  0.055697  0.056016\n",
              "7  0.055704  0.055689  0.888607"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJNLnxueWEOW"
      },
      "source": [
        "You can clearly see which documents contribute the most to which of the three topics in the above output. You can view the topics and their main constituents as follows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU9FCTrRV9yG",
        "outputId": "e7603a18-fbc5-4c33-b7ea-71b267da9b9e"
      },
      "source": [
        "tt_matrix = lda.components_\r\n",
        "for topic_weights in tt_matrix:\r\n",
        "    topic = [(token, round(weight, 3)) for token, weight in zip(vocab, topic_weights)]\r\n",
        "    topic = sorted(topic, key=lambda x: -x[1])\r\n",
        "    topic = [item for item in topic if item[1] > 0.6]\r\n",
        "    print(topic)\r\n",
        "    print()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('sky', 4.332), ('blue', 3.374), ('beautiful', 3.332), ('today', 1.333), ('love', 1.33)]\n",
            "\n",
            "[('bacon', 2.333), ('eggs', 2.333), ('ham', 2.333), ('sausages', 2.333), ('love', 1.335), ('beans', 1.333), ('breakfast', 1.333), ('green', 1.333), ('kings', 1.333), ('toast', 1.333)]\n",
            "\n",
            "[('brown', 3.332), ('dog', 3.332), ('fox', 3.332), ('lazy', 3.332), ('quick', 3.332), ('jumps', 1.332), ('blue', 1.292)]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koxA_65aWVE-"
      },
      "source": [
        "Thus you can clearly see the three topics are quite distinguishable from each other based on their constituent terms, first one talking about weather, second one about food and the last one about animals. Choosing the number of topics for topic modeling is an entire topic on its own (pun not intended!) and is an art as well as a science."
      ]
    }
  ]
}